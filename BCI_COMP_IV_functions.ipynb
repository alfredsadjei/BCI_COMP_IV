{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractInfo(data,nSamples):\n",
    "    \"\"\"Extract relevant information from the matlab data object\"\"\"\n",
    "    \n",
    "    channelNames = [channel[0] for channel in data[\"nfo\"][0][0][2][0]]\n",
    "\n",
    "    #Extracting Sampling Rate\n",
    "    sRate = data[\"nfo\"][0][0][0][0][0]\n",
    "\n",
    "    # Extracting class labels\n",
    "    classLabels = list(map(lambda x : x[0], data[\"nfo\"][0][0][1][0]))\n",
    "\n",
    "    #Extracting event onset data\n",
    "    eventOnsets = data[\"mrk\"][0][0][0]\n",
    "\n",
    "    #Extracting event code data\n",
    "    eventCodes = data[\"mrk\"][0][0][1]\n",
    "\n",
    "    #labels for each eeg data sample\n",
    "    labels  = np.zeros((1,nSamples),dtype=int)\n",
    "\n",
    "    # Set labels positions to event codes using eventOnsets as indexes\n",
    "    # This ensure that data samples that arent associated with any event have a target value of zero\n",
    "\n",
    "    labels[0,eventOnsets] = eventCodes\n",
    "\n",
    "    return channelNames,sRate,classLabels,eventOnsets,eventCodes,labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrials(labels, uniqueEventCodes, trialWindow,eeg,eventCodes_train_test,eventOnsets_train_test,nChannels,selectedChannels=None):\n",
    "\n",
    "    \"\"\"Extract trials from continuous EEG data \n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    labels - An Array containing the class labels (left and right)\n",
    "\n",
    "    uniqueEventCodes - Event codes corresponding to a particular label (-1 and 1)\n",
    "\n",
    "    trialWindow - An array containing values representing the trial window. This array is added \n",
    "                  to a given event onset time sample point to extract the effective trial window\n",
    "    \n",
    "    eeg - 2D array of shape channel x samples\n",
    "\n",
    "    eventOnsets_train_test - An array containing the event onset from which to extract trials \n",
    "    \n",
    "    eventCodes_train_test - An array containing the event codes corresponding to the given event onsets\n",
    "\n",
    "    nChannels - The number of channels in the data\n",
    "\n",
    "    selectedChannels - An array containing specific channels from which to extract data\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trials - a dictionary object containing extracted trials for the given motor imagery classes\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #In order to obtain the appropriate trials for this dataset, we need to define a time window for epoching the data.\n",
    "\n",
    "    #The NFFT param value for the PSD function must be exactly half of the length of the\n",
    "    # sample window + 1\n",
    "    #It seems that increasing the length of the time window increases the classification accuracy but only up on until \n",
    "    # time samples\n",
    "    #Create visual representaion for this.\n",
    "    #It may be useful to show also the effect of shifting the start time of the window 0.0, 0.1, 0.2 etc\n",
    "\n",
    "    trials = {}\n",
    "\n",
    "    for cls, code in zip(labels,uniqueEventCodes):\n",
    "\n",
    "        #Get all event onsets for the particular class\n",
    "        # Create a filter array i.e return an array with True\n",
    "        # values at all indeces where the eventCode = code\n",
    "        # and False otherwise\n",
    "\n",
    "        filter_arr = eventCodes_train_test == code\n",
    "\n",
    "        # use arr to filter event onsest specific to this class\n",
    "        clsOnsets = eventOnsets_train_test[filter_arr]\n",
    "        \n",
    "        #Allocate memmory for trial\n",
    "        trials[cls] = np.zeros(\n",
    "            (nChannels if selectedChannels is None else len(selectedChannels), len(clsOnsets), len(trialWindow)))\n",
    "        \n",
    "        #Extract trials for the class\n",
    "        \n",
    "        for i, onset in enumerate(clsOnsets):\n",
    "            #For all 59 channels extract class trials of size onset + win from\n",
    "            # Each onsent represents the start time of an external cue\n",
    "            #Each row is a list of the values for each channel of the 59 channels recorded\n",
    "            #within the time window of interest\n",
    "                \n",
    "            lastI = onset + len(trialWindow)\n",
    "                \n",
    "            selectedWindow = eeg[:,onset+trialWindow]\n",
    "\n",
    "                \n",
    "            trials.get(cls)[:,i,:] = selectedWindow if selectedChannels is None else selectedWindow[selectedChannels,:]\n",
    "        \n",
    "    \n",
    "    return trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def getFilteredTrials(trials, trialWin,nChannels,sRate,b=None,a=None,selectedChannels=None):\n",
    "    \"\"\"Extract filtered trials \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trials - a dictionary object containing extracted trials the given motor imagery classes\n",
    "\n",
    "    trialWin - An array containing values representing the trial window. This array is added \n",
    "                  to a given event onset time sample point to extract the effective trial window\n",
    "    \n",
    "    nChannels - The number of channels in the data\n",
    "\n",
    "    sRate - The sampling rate\n",
    "\n",
    "    b - numerator (b)  coefficients of an iirfilter\n",
    "\n",
    "    a - denominator (a) coefficients of an iirfilter\n",
    "\n",
    "    selectedChannels - An array containing specific channels from which to extract data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trials_filt: A dictionary object contatining filtered trials for the given motor imagery classes\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    trials_filt = {}\n",
    "\n",
    "    def bandPass(trial_lr,lowcut,highcut,fs):\n",
    "        nonlocal b, a\n",
    "        \"\"\"Bandpass filter \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        trial_lr: A 3D ndarray of shape (channels x trials x time) which contains the trials per channels\n",
    "\n",
    "        lowcut: Lower frequency bound in Hz\n",
    "\n",
    "        highcut: Higher frequency bound in Hz\n",
    "        \n",
    "        fs: Sampling frequency\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        trials_filt: A 3D ndarray of shape (channels x trials x time) which contains the bandpass filtered trials per channels\n",
    "        \"\"\"\n",
    "        nqfreq = 0.5*fs\n",
    "        \n",
    "        if b is None and a is None:\n",
    "            b , a = signal.iirfilter(4,[lowcut/nqfreq,highcut/nqfreq])\n",
    "\n",
    "        nTrials = trial_lr.shape[1]\n",
    "        filt_trials = np.zeros((nChannels if selectedChannels is None else len(selectedChannels),nTrials,len(trialWin)))\n",
    "\n",
    "\n",
    "        for t in range(nTrials):\n",
    "            filt_trials[:,t,:] = signal.filtfilt(b,a,trial_lr[:,t,:],axis=1)\n",
    "\n",
    "        return filt_trials\n",
    "\n",
    "    trials_filt[\"left\"] = bandPass(trials[\"left\"],8,12,sRate)\n",
    "    trials_filt[\"right\"] = bandPass(trials[\"right\"],8,12,sRate)\n",
    "\n",
    "    return trials_filt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import mlab\n",
    "\n",
    "def psd(trials, trialWindow, nChannels, sRate):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    trials: A 3D ndarray of shape (channels x trials x time)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trials_PSD: A 3D ndarray of shape (channels x trials x PSD) the PSD for each trial\n",
    "    \"\"\"\n",
    "\n",
    "    nTrials = trials.shape[1]\n",
    "    trials_PSD = np.zeros((nChannels,nTrials, int(len(trialWindow)/2)+1)) #Why?\n",
    "\n",
    "    for trial in range(nTrials):\n",
    "        for ch in range(nChannels):\n",
    "            #Calculate the PSD\n",
    "            \n",
    "            (PSD, freqs) = mlab.psd(trials[ch, trial , :], NFFT=len(trialWindow), Fs=sRate)\n",
    "            trials_PSD[ch, trial, :] = PSD\n",
    "\n",
    "    return trials_PSD, freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_psd(trial_PSDs,freqs,channel_IDXs,ymax):\n",
    "\n",
    "    \"\"\" Plot the mean Power Spectral Density of left and right hand signals from \n",
    "        all trials at the given electrode channels \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    nChans = len(channel_IDXs)\n",
    "    nRows = int(np.ceil(nChans/3))\n",
    "    nCols = min(3,nChans)\n",
    "\n",
    "    #for channels in channel indexes\n",
    "    for i,ch in enumerate(channel_IDXs):\n",
    "        plt.subplot(nRows,nCols,i+1)\n",
    "\n",
    "        for cls in trial_PSDs.keys():\n",
    "            plt.plot(freqs,np.mean(trial_PSDs[cls][ch,:,:],axis=0),label=cls)\n",
    "\n",
    "        #plt.fill_betweenx(np.mean(trial_PSDs[\"left\"][ch,:,:],axis=0), 8, 12, color=\"green\", alpha=0.2)\n",
    "\n",
    "        plt.xlabel(\"Frequency in Hz\")\n",
    "        \n",
    "        plt.xlim(1,30)\n",
    "        plt.grid()\n",
    "        plt.ylim(0,ymax)\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following the standard bci classification paradigm outlined in \"The non-invasive Berlin Brain–Computer Interface: Fast acquisition of effective performance in untrained subjects\"\n",
    "#Benjamin Blankertz,a,⁎ Guido Dornhege,a Matthias Krauledat,a,b Klaus-Robert Müller, and Gabriel Curio\n",
    "\n",
    "def logvar(trials):\n",
    "    #trials has a shape of 59 x 100 x 200\n",
    "    return np.log(np.var(trials,axis=2))\n",
    "    #calculate variance along the sample (time sample) axis\n",
    "    #then calculate the log of the result\n",
    "\n",
    "    # Since VARIANCE of band-pass filtered signals\n",
    "    # is equal to band-power, CSP analysis is applied\n",
    "    # to approximately band-pass filtered signals in order\n",
    "    # to obtain an effective discrimination of mental states\n",
    "    # that are characterized by ERD/ERS effects ref:Optimizing Spatial filters for Robust EEG Single-Trial Analysis\n",
    "\n",
    "    # The log of the variance can be useful for data that exhibits exponential or power-law relationships,\n",
    "    # as it can help to compress the range of the data and make it easier to visualize and analyze.\n",
    "\n",
    "    # For example, consider a set of spatial filters with variances[1, 10, 100]. The log of the variances\n",
    "    # would be[0, 1, 2], which has a smaller range than the original data. This can be useful for data that\n",
    "    # has a wide range of values, as it can make it easier to visualize and analyze the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_logvar(trials, nChannels, classLabels):\n",
    "    \"\"\" Plot the mean log-var (logarithm of the variance) \"\"\"\n",
    "    plt.figure(figsize=(12,5))\n",
    "\n",
    "    x0 = np.arange(nChannels)\n",
    "    x1 = np.arange(nChannels) + 0.4\n",
    "\n",
    "    y0 = np.mean(trials[\"left\"],axis=1)\n",
    "    y1 = np.mean(trials[\"right\"],axis=1)\n",
    "\n",
    "    #axis 1 refers to the axis at position 1 in the dimension tuple\n",
    "    #in this case, the dimension tuple of trials[\"left\"] or trials[\"right\"]\n",
    "    # is (59,100)\n",
    "    #Hence the mean is calculated along the axis with 100 values\n",
    "    #Leaving a vector of shape (59,)\n",
    "\n",
    "\n",
    "    plt.bar(x0,y0, width=0.5, color=\"b\")\n",
    "    plt.bar(x1,y1, width=0.4, color=\"r\")\n",
    "\n",
    "    plt.xlim(-0.5,nChannels+0.5)\n",
    "\n",
    "    plt.gca().yaxis.grid(True)\n",
    "    plt.title(\"log-var of each channel\")\n",
    "    plt.xlabel(\"channels\")\n",
    "    plt.ylabel(\"log-var\")\n",
    "    plt.legend(classLabels)\n",
    "\n",
    "    #A plot of the log of the variance of the CSP transformed data can be useful for identifying patterns or\n",
    "    # trends in the data that may be indicative of differences between the two classes of signals.\n",
    "    # For example, if the log of the variance of the CSP transformed data is higher for one class than the\n",
    "    # other, it could indicate that the filters for that class are more discriminative.\n",
    "\n",
    "    # To choose the subset of filters that are most discriminative between the two classes of signals,\n",
    "    # it may be useful to plot the log of the variance of the CSP transformed data and examine the patterns\n",
    "    # or trends that emerge. The filters with the highest variance could be selected as the most discriminative,\n",
    "    # as they may contain the most information about the differences between the two classes.\n",
    "\n",
    "    #In the case below, it seems that the log of the variance of spatial filter 0 (column 0) is at its highest for\n",
    "    #left hand signals and its lowest for right hand singals, whereas, spatial filter 59, has its log-var at its highest\n",
    "    #right hand signals and its lowest for left hand signals. Hence, for each signal window (shape 59 x 1 x 200)\n",
    "    # We can extract the two most relevant spatial filters to determine whether it represents left or right.\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg\n",
    "\n",
    "def cov(trials):\n",
    "    \"\"\"Calculate the covariance for each trial and return their average\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trials - Array (channels x trials x samples) \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A covariance matrix containing the mean values of all covariance matrices generated from trials\n",
    "    \"\"\"\n",
    "    ntrials = trials.shape[1]\n",
    "\n",
    "    #Select all 59 channels (59 rows), then select the ith trial\n",
    "    #for each of those 59 rows along with all the columns (values) for that\n",
    "    # trial (resulting in a 59 x 200 matrix) and calculate the covariance matrix\n",
    "\n",
    "    covs = [np.cov(trials[:,i,:]) for i in range(ntrials)]\n",
    "\n",
    "    # covs consists of nTrials x 59 x 59 matrices\n",
    "    #Since covariance is calculated by the dot product of X and X.T\n",
    "    #Where X.T is the transpose of X [(59 x 200).dot((200 x 59))]\n",
    "\n",
    "    #print(np.array(covs).shape)\n",
    "\n",
    "    return np.mean(covs, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitening(sigma):\n",
    "    \"\"\"Calculate a whitening matrix for covariance matrix sigma.\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    sigma - A covariance matrix of shape N x N, where N is the number of channels for a given\n",
    "            trial. \n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    The whitened covariance matrix\n",
    "\n",
    "    \"\"\"\n",
    "    #In singular value decomposition(SVD), a matrix is decomposed into the product of\n",
    "    # three matrices: a left singular matrix, a diagonal matrix, and a right singular matrix.\n",
    "    # The diagonal matrix, called the singular value matrix, contains the singular values of the\n",
    "    # original matrix. The left and right singular matrices contain the left and right singular\n",
    "    # vectors, respectively.\n",
    "\n",
    "    # A whitening matrix is a diagonal matrix that is used to transform the singular value matrix\n",
    "    # so that it has the identity matrix as its diagonal. This is done by dividing each element on the\n",
    "    # diagonal of the singular value matrix by the square root of the corresponding singular value.\n",
    "\n",
    "    # The whitening matrix is useful in SVD because it can be used to decorrelate the singular vectors,\n",
    "    # which can simplify certain computations and make it easier to interpret the results of\n",
    "    # the decomposition. For example, in dimensionality reduction, whitening the singular value matrix\n",
    "    # can help to remove some of the redundancy in the data and make it easier to identify the underlying\n",
    "    # structure of the data.\n",
    "\n",
    "    U, l, _ = linalg.svd(sigma) # l is a vector of singular values U is the left singular matrix\n",
    "    return U.dot(np.diag(l ** -0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csp(trials_r, trials_l):\n",
    "    \"\"\"Calculate the CSP transformation matrix W\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    trials_r - Array(channels x trials x samples) containing right hand movement trials\n",
    "    trials_l - Array(channels x trials x samples) containing left hand movement trials\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Mixing matrix W\n",
    "    \"\"\"\n",
    "    cov_r = cov(trials_r)\n",
    "    cov_l = cov(trials_l)\n",
    "    P = whitening(cov_r + cov_l)\n",
    "\n",
    "    B, _, _ = linalg.svd(P.T.dot(cov_r).dot(P))\n",
    "\n",
    "    W = P.dot(B)\n",
    "\n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mix(W, trials, trialWin, nChannels, selectedChannels=None):\n",
    "    \"\"\"Apply a mixing matrix to each trial (basically multiply W with the EEG signal matrix)\"\"\"\n",
    "    ntrials = trials.shape[1]\n",
    "\n",
    "\n",
    "    trials_csp = np.zeros((nChannels if selectedChannels is None else len(selectedChannels) , ntrials, len(trialWin)))\n",
    "\n",
    "\n",
    "    for i in range(ntrials):\n",
    "        trials_csp[:,i,:] = W.T.dot(trials[:,i,:])\n",
    "\n",
    "    return trials_csp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(left,right,classLabels):\n",
    "    \"\"\" Display scatter plot of the distribution left and right motor imagery trials\"\"\"\n",
    "    plt.figure()\n",
    "    plt.scatter(left[0,:],left[-1,:],color=\"b\")\n",
    "    plt.scatter(right[0,:],right[-1,:],color=\"r\")\n",
    "    plt.xlabel(\"First Component\")\n",
    "    plt.ylabel(\"Last Component\")\n",
    "    plt.legend(classLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def label_data(data,label,foldNum):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data - An array of dimensions observation x features\n",
    "    label the desired label\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    newData - An dataframe of with columns F1...Fn and label\n",
    "    \"\"\"\n",
    "\n",
    "    nTrainSamples = data.shape[0]\n",
    "    nFeatures = data.shape[1]\n",
    "\n",
    "    featureColumns = [f\"F{x}\" for x in range(1,nFeatures+1)]\n",
    "\n",
    "    newData = pd.DataFrame(data,columns=featureColumns)\n",
    "\n",
    "    newData[\"Labels\"] = np.array([label for x in range(nTrainSamples)])\n",
    "\n",
    "    # Apply fold num\n",
    "    newData[\"Fold\"] = np.random.randint(1,foldNum+1,nTrainSamples)\n",
    "\n",
    "    return newData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def featureExtraction(data, split_percentage, b=None, a=None, selectedChannels=None, trialWinStart=0.5, trialWinEnd=2.5):\n",
    "\n",
    "    \"\"\"Extract csp features from training data\"\"\"\n",
    "    \n",
    "    eeg = data[\"cnt\"].T \n",
    "\n",
    "    nChannels, nSamples = eeg.shape\n",
    "\n",
    "    channelNames,sRate,classLabels,eventOnsets,eventCodes,labels = extractInfo(data,nSamples)\n",
    "\n",
    "\n",
    "    trialWindow = np.arange(int(trialWinStart*sRate),int(trialWinEnd*sRate))\n",
    "\n",
    "    trials = getTrials(classLabels,\n",
    "                        np.unique(eventCodes),\n",
    "                        trialWindow,\n",
    "                        eeg,\n",
    "                        eventCodes,\n",
    "                        eventOnsets,\n",
    "                        nChannels,\n",
    "                        selectedChannels = selectedChannels)\n",
    "\n",
    "    \n",
    "\n",
    "    filteredTrials = getFilteredTrials(trials,\n",
    "                                       trialWindow,\n",
    "                                       nChannels,\n",
    "                                       sRate,\n",
    "                                       selectedChannels=selectedChannels,\n",
    "                                       b=b,\n",
    "                                       a=a)\n",
    "\n",
    "    train = {\"left\": filteredTrials[\"left\"],\n",
    "            \"right\": filteredTrials[\"right\"]}\n",
    "\n",
    "    W = csp(train[\"right\"],train[\"left\"])\n",
    "\n",
    "    train = {\n",
    "    \"left\" : apply_mix(W,train[\"left\"],trialWindow,nChannels,selectedChannels=selectedChannels),\n",
    "    \"right\" : apply_mix(W,train[\"right\"],trialWindow,nChannels,selectedChannels=selectedChannels)\n",
    "    }\n",
    "\n",
    " \n",
    "    train[\"left\"] = logvar(train[\"left\"])\n",
    "    train[\"right\"] = logvar(train[\"right\"])\n",
    "\n",
    "    comp = [-1, 0]\n",
    "\n",
    "    train[\"left\"] = train[\"left\"][comp,:]\n",
    "    train[\"right\"] = train[\"right\"][comp,:]\n",
    "\n",
    "    train_l_df = label_data(train[\"left\"].T,\"l\",5)\n",
    "    train_r_df = label_data(train[\"right\"].T,\"r\",5)\n",
    "\n",
    "    train_comb = pd.concat([train_l_df,train_r_df])\n",
    "\n",
    "    if split_percentage < 1:\n",
    "\n",
    "        train_comb, test_comb = train_test_split(train_comb, train_size=split_percentage,random_state=42)\n",
    "\n",
    "        return train_comb, test_comb, W, comp\n",
    "\n",
    "    return train_comb, W, comp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def testClassifier(rawData,trialWinStart,trialWinEnd,percentSplit,model,b=None,a=None,selectedChannels=None):\n",
    "\n",
    "    \"\"\" Extract the best classifier performace from training data \"\"\"\n",
    "    \n",
    "    #It may not yield the best results testing this classifier on data with a different trial \n",
    "    # width or start time since the data being tested is extracted using a different decomposition matrix (W) from the \n",
    "    # CSP algorithm. As the classifier being tested was initially fit to data extracted using a different decompostion matrix, \n",
    "    # poor performance is a likely result. It may be that in order to test the effect of increasing or decreasing the trial window \n",
    "    # length or the trial window start point, entirely new classifier tuning is required for each new window.\n",
    "    \n",
    "    \n",
    "    trainData, _, _, _ = featureExtraction(rawData,percentSplit,\n",
    "                                                        selectedChannels=selectedChannels,\n",
    "                                                        trialWinStart=trialWinStart,\n",
    "                                                        trialWinEnd=trialWinEnd,\n",
    "                                                        b = b,\n",
    "                                                        a = a)\n",
    "\n",
    "    nCols = len(trainData.columns)\n",
    "    ########################################## CLASSIFIER TUNING ####################################################\n",
    "\n",
    "    ########################################## LINEAR DISCRIMINANT ANALYSIS #########################################\n",
    "    \n",
    "    if model == \"LDA\":\n",
    "        param_grid_LDA = {'solver': ['svd', 'lsqr', 'eigen'],'shrinkage':np.arange(0,1,0.1)}\n",
    "        gridLDA = GridSearchCV(estimator=LDA(), param_grid=param_grid_LDA,scoring=\"accuracy\", cv=5)\n",
    "        gridLDA.fit(trainData.iloc[:,:nCols-2], trainData.iloc[:,nCols-2])\n",
    "\n",
    "        return gridLDA.best_score_, gridLDA.best_estimator_\n",
    "\n",
    "\n",
    "    ######################################### LOGISTIC REGRESSION #####################################################\n",
    "\n",
    "    if model == \"Logistic Regression\":\n",
    "        param_grid_LR = {'penalty': ['l1','l2'], 'C':np.logspace(-3,3), 'solver': ['newton-cg', 'lbfgs', 'liblinear']}\n",
    "        gridLR = GridSearchCV(estimator=LogisticRegression(), param_grid=param_grid_LR,scoring=\"accuracy\", cv=5)\n",
    "        gridLR.fit(trainData.iloc[:,:nCols-2], trainData.iloc[:,nCols-2])\n",
    "\n",
    "        \n",
    "        return gridLR.best_score_, gridLR.best_estimator_\n",
    "\n",
    "\n",
    "    ######################################### SUPPORT VECTOR CLASSIFIER #################################################\n",
    "\n",
    "    if model == \"SVC\":\n",
    "        param_grid_SVC = {'C': [0.0001,0.001,0.01,1,10,100,1000],\n",
    "                          'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                          'kernel': [\"linear\",'rbf']}\n",
    "        gridSVC = GridSearchCV(estimator=SVC(), param_grid=param_grid_SVC,scoring=\"accuracy\", cv=5)\n",
    "        gridSVC.fit(trainData.iloc[:,:nCols-2], trainData.iloc[:,nCols-2])\n",
    "\n",
    "    \n",
    "        return gridSVC.best_score_ , gridSVC.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startRunningClassifier(testData,calibratedModel,comp,W_train, trialWinStart,trialWinEnd,b=None, a=None):\n",
    "    \"\"\" Extract class probabilities from evaluation test data for each time sample\"\"\"\n",
    "    \n",
    "    #Extracting Sampling Rate\n",
    "    sRate = testData[\"nfo\"][0][0][0][0][0]\n",
    "\n",
    "    testEEG = testData[\"cnt\"].T \n",
    "   \n",
    "    nSamples = testEEG.shape[1] \n",
    "\n",
    "    trialWindow = np.arange(int(trialWinStart*sRate),int(trialWinEnd*sRate))\n",
    "\n",
    "    preds = []\n",
    "  \n",
    "    try:\n",
    "        for i in range(nSamples):\n",
    "            \n",
    "            #capture signal in sliding window\n",
    "            captured_signal = testEEG[:,i+trialWindow]\n",
    "            \n",
    "            #filter captured signal\n",
    "            nqfreq = 0.5*sRate\n",
    "\n",
    "            if b is None and a is None:\n",
    "                b , a = signal.iirfilter(6,[8/nqfreq,12/nqfreq])\n",
    "\n",
    "            filtered_test_trial = signal.filtfilt(b,a,captured_signal,axis=1)\n",
    "\n",
    "            #Extract features from transformed data\n",
    "            spatialFilters = W_train.T.dot(filtered_test_trial)\n",
    "\n",
    "            spatialFilters = spatialFilters[comp,:]\n",
    "\n",
    "            features = np.log(np.var(spatialFilters,axis=1)).T\n",
    "\n",
    "            features = pd.DataFrame([features],columns=[\"F1\",\"F2\"])\n",
    "\n",
    "            classProbabilities = calibratedModel.predict_proba(features)\n",
    "\n",
    "            preds.extend(classProbabilities)\n",
    "    \n",
    "    except IndexError:\n",
    "        pass\n",
    "       \n",
    "    \n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFilterBank(fs):\n",
    "    \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        fs: Sampling frequency\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        filterBank: A dictionary with keys represented by a frequency band; (lower bound, upper bound)\n",
    "                    and values as numerator (b) and denominator (a) coefficients of the iirfilter\n",
    "    \"\"\"\n",
    "    \n",
    "    filterBank = {}\n",
    "\n",
    "    freq_bands = [(8,12),(8,15),(13,30)]\n",
    "\n",
    "    for lowcut, highcut in freq_bands:\n",
    "        nqfreq = 0.5*fs\n",
    "        b , a = signal.iirfilter(4,[lowcut/nqfreq,highcut/nqfreq])\n",
    "        filterBank[(lowcut,highcut)] = (b,a)\n",
    "\n",
    "    return filterBank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWindowLength(data,modelNames,scoring,split):\n",
    "\n",
    "    \"\"\" Extract best performance from trial window length tuning \"\"\"\n",
    "    \n",
    "    bestTime = None\n",
    "    bestPerformance = 0\n",
    "    bestEstimator = None\n",
    "    \n",
    "    for model in modelNames:\n",
    "        \n",
    "        accVals = {}\n",
    "        bestModelPerformance = 0\n",
    "        bestModelEstimator = None\n",
    "\n",
    "        for i in np.linspace(1,5,9):\n",
    "            accVals[i-0.5], estimator = testClassifier(data,0.5,i,split,model)\n",
    "            \n",
    "            if accVals[i-0.5] > bestModelPerformance:\n",
    "                bestModelPerformance = accVals[i-0.5]\n",
    "                bestModelEstimator = estimator\n",
    "                bestTime = i-0.5\n",
    "\n",
    "        if bestModelPerformance > bestPerformance:\n",
    "            bestPerformance = bestModelPerformance\n",
    "            bestEstimator = bestModelEstimator\n",
    "\n",
    "        #plot acc Val\n",
    "        x, y = zip(*accVals.items())\n",
    "        plt.plot(x,y,label=f\"{model}({bestModelPerformance})\")\n",
    "    \n",
    "    plt.axvline(x=bestTime, color='purple', ls='--', lw=1.5, label=f\"Best window length ({bestTime})\")\n",
    "    plt.legend()\n",
    "    \n",
    "\n",
    "    return bestEstimator\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWindowStartTime(data,modelNames,scoring,split,bestLen,times=None):\n",
    "\n",
    "    \"\"\" Extract best performance from trial window start time tuning \"\"\"\n",
    "\n",
    "    bestTime = None\n",
    "    bestPerformance = 0\n",
    "    bestEstimator = None\n",
    "\n",
    "    for model in modelNames:\n",
    "\n",
    "        accVals = {}\n",
    "        bestModelPerformance = 0\n",
    "        bestModelEstimator = None\n",
    "        \n",
    "        times = np.arange(0,2.1,0.1) if times is None else times\n",
    "        for i in times:\n",
    "            accVals[i], estimator = testClassifier(data,i,i+bestLen,split,model)\n",
    "\n",
    "            if accVals[i] > bestModelPerformance:\n",
    "                bestModelPerformance = accVals[i]\n",
    "                bestModelEstimator = estimator\n",
    "                bestTime = i\n",
    "\n",
    "        if bestModelPerformance > bestPerformance:\n",
    "            bestPerformance = bestModelPerformance\n",
    "            bestEstimator = bestModelEstimator\n",
    "\n",
    "\n",
    "        x, y = zip(*accVals.items())\n",
    "        plt.plot(x,y,label=f\"{model}({bestModelPerformance})\")\n",
    "   \n",
    "    plt.axvline(x=bestTime, color='purple', ls='--', lw=1.5, label=f\"Best start time({bestTime})\")\n",
    "    plt.legend()\n",
    "    \n",
    "    return bestEstimator\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testFrequencyBand(rawData,modelNames,filterBank,split,selectedChannels=None, trialWinStart=None, trialWinEnd=None):\n",
    "\n",
    "    \"\"\" Extract best performance from frequency band tuning \"\"\"\n",
    "\n",
    "\n",
    "    totalBestBandAcc = 0\n",
    "    bandFreqRes = {}\n",
    "    bestEstimator = None\n",
    "    \n",
    "    bestBand = None\n",
    "    \n",
    "    for lower,upper in filterBank.keys():\n",
    "\n",
    "        b, a = filterBank[lower,upper]\n",
    "        \n",
    "        bestBandAccVal = 0\n",
    "        bestBandEstimator = None\n",
    "\n",
    "        for model in modelNames:\n",
    "            accVal, estimator = testClassifier(rawData,trialWinStart,trialWinEnd,split,model,b=b,a=a)\n",
    "\n",
    "            if accVal > bestBandAccVal:\n",
    "                bestBandAccVal = accVal\n",
    "                bestBandEstimator = estimator\n",
    "        \n",
    "        if bestBandAccVal > totalBestBandAcc:\n",
    "            bestBand = lower,upper\n",
    "            totalBestBandAcc = bestBandAccVal\n",
    "            bestEstimator = bestBandEstimator\n",
    "\n",
    "        bandFreqRes[lower,upper] = (b,a)\n",
    "        print(f\"{lower}-{upper} : {bestBandAccVal}\")\n",
    "\n",
    "    \n",
    "\n",
    "    return bestBand, bestEstimator, bandFreqRes[bestBand]\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
