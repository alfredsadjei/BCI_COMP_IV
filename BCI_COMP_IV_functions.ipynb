{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractInfo(data,nSamples):\n",
    "    \"\"\"Extract relevant information from the matlab data object\"\"\"\n",
    "    \n",
    "    channelNames = [channel[0] for channel in data[\"nfo\"][0][0][2][0]]\n",
    "\n",
    "    #Extracting Sampling Rate\n",
    "    sRate = data[\"nfo\"][0][0][0][0][0]\n",
    "\n",
    "    # Extracting class labels\n",
    "    classLabels = list(map(lambda x : x[0], data[\"nfo\"][0][0][1][0]))\n",
    "\n",
    "    #Extracting event onset data\n",
    "    eventOnsets = data[\"mrk\"][0][0][0]\n",
    "\n",
    "\n",
    "    #Extracting event code data\n",
    "    eventCodes = data[\"mrk\"][0][0][1]\n",
    "\n",
    "    #labels for each eeg data sample\n",
    "    labels  = np.zeros((1,nSamples),dtype=int)\n",
    "\n",
    "    # Set labels positions to event codes using eventOnsets as indexes\n",
    "    # This ensure that data samples that arent associated with any event have a target value of zero\n",
    "\n",
    "    labels[0,eventOnsets] = eventCodes\n",
    "\n",
    "    return channelNames,sRate,classLabels,eventOnsets,eventCodes,labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrials(labels, uniqueEventCodes, trialWindow,eeg,eventCodes_train_test,eventOnsets_train_test,sRate, nChannels,selectedChannels=None):\n",
    "\n",
    "    \"\"\"Extract trials from continuous EEG data \n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    labels - An Array containing the class labels (left and right)\n",
    "\n",
    "    uniqueEventCodes - Event codes corresponding to a particular label (-1 and 1)\n",
    "\n",
    "    trialWindow - An array containing values representing the trial window. This array is added \n",
    "                  to a given event onset time sample point to extract the effective trial window\n",
    "    \n",
    "    eeg - 2D array of shape channel x samples\n",
    "\n",
    "    eventOnsets_train_test - An array containing the event onset from which to extract trials \n",
    "    \n",
    "    eventCodes_train_test - An array containing the event codes corresponding to the given event onsets\n",
    "\n",
    "    nChannels - The number of channels in the data\n",
    "\n",
    "    selectedChannels - An array containing specific channels from which to extract data\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trials - a dictionary object containing extracted trials for the given motor imagery classes\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #In order to obtain the appropriate trials for this dataset, we need to define a time window for epoching the data.\n",
    "\n",
    "    #The NFFT param value for the PSD function must be exactly half of the length of the\n",
    "    # sample window + 1\n",
    "    #It seems that increasing the length of the time window increases the classification accuracy but only up on until \n",
    "    # time samples\n",
    "    #Create visual representaion for this.\n",
    "    #It may be useful to show also the effect of shifting the start time of the window 0.0, 0.1, 0.2 etc\n",
    "\n",
    "    trials = {}\n",
    "\n",
    "    idleStateTrials = {}\n",
    "\n",
    "    \n",
    "    \n",
    "    for cls, code in zip(labels,uniqueEventCodes):\n",
    "\n",
    "        #Get all event onsets for the particular class\n",
    "        # Create a filter array i.e return an array with True\n",
    "        # values at all indeces where the eventCode = code\n",
    "        # and False otherwise\n",
    "\n",
    "        filter_arr = eventCodes_train_test == code\n",
    "\n",
    "        # use arr to filter event onsest specific to this class\n",
    "        clsOnsets = eventOnsets_train_test[filter_arr]\n",
    "        \n",
    "        #Allocate memmory for trial\n",
    "        trials[cls] = np.zeros(\n",
    "            (nChannels if selectedChannels is None else len(selectedChannels), len(clsOnsets), len(trialWindow)))\n",
    "        \n",
    "        idleStateTrials[cls] = np.zeros(\n",
    "            (nChannels if selectedChannels is None else len(selectedChannels), len(clsOnsets), len(trialWindow)))\n",
    "        \n",
    "        \n",
    "        #Extract trials for the class\n",
    "\n",
    "        #make third class? Yes\n",
    "        \n",
    "        for i, onset in enumerate(clsOnsets):\n",
    "            #For all 59 channels extract class trials of size onset + win from\n",
    "            # Each onsent represents the start time of an external cue\n",
    "            #Each row is a list of the values for each channel of the 59 channels recorded\n",
    "            #within the time window of interest\n",
    "                \n",
    "            selectedWindow = eeg[:,onset+trialWindow] \n",
    "            # print(f\"selected window shape: {selectedWindow.shape}\")\n",
    "\n",
    "            # initialize selectedIdleState with zeros\n",
    "            selectedIdleState = np.zeros((nChannels, 4*sRate))\n",
    "\n",
    "            start_index = onset + (4 * sRate)\n",
    "            end_index = start_index + trialWindow.shape[0]\n",
    "\n",
    "            if end_index > eeg.shape[1]:\n",
    "                # if the end index is out of range for eeg, extract the valid portion of eeg\n",
    "                valid_eeg = eeg[:, start_index:]\n",
    "                # copy the valid portion of eeg into the corresponding portion of selectedIdleState\n",
    "                selectedIdleState[:, :valid_eeg.shape[1]] = valid_eeg\n",
    "            else:\n",
    "                # if the slice is entirely within the bounds of eeg, extract it directly\n",
    "                selectedIdleState[:, :trialWindow.shape[0]] = eeg[:, start_index:end_index]\n",
    "                \n",
    "            trials.get(cls)[:,i,:] = selectedWindow if selectedChannels is None else selectedWindow[selectedChannels,:]\n",
    "            idleStateTrials.get(cls)[:,i,:] = selectedIdleState if selectedChannels is None else selectedIdleState[selectedChannels,:]\n",
    "            \n",
    "    \n",
    "    return trials, idleStateTrials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def getFilteredTrials(trials, trialWin,nChannels,sRate,b=None,a=None,selectedChannels=None, classLabels=None):\n",
    "    \"\"\"Extract filtered trials \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trials - a dictionary object containing extracted trials the given motor imagery classes\n",
    "\n",
    "    trialWin - An array containing values representing the trial window. This array is added \n",
    "                  to a given event onset time sample point to extract the effective trial window\n",
    "    \n",
    "    nChannels - The number of channels in the data\n",
    "\n",
    "    sRate - The sampling rate\n",
    "\n",
    "    b - numerator (b)  coefficients of an iirfilter\n",
    "\n",
    "    a - denominator (a) coefficients of an iirfilter\n",
    "\n",
    "    selectedChannels - An array containing specific channels from which to extract data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trials_filt: A dictionary object contatining filtered trials for the given motor imagery classes\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    trials_filt = {}\n",
    "\n",
    "    def bandPass(trial_lr,lowcut,highcut,fs):\n",
    "        nonlocal b, a\n",
    "        \"\"\"Bandpass filter \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        trial_lr: A 3D ndarray of shape (channels x trials x time) which contains the trials per channels\n",
    "\n",
    "        lowcut: Lower frequency bound in Hz\n",
    "\n",
    "        highcut: Higher frequency bound in Hz\n",
    "        \n",
    "        fs: Sampling frequency\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        trials_filt: A 3D ndarray of shape (channels x trials x time) which contains the bandpass filtered trials per channels\n",
    "        \"\"\"\n",
    "        nqfreq = 0.5*fs\n",
    "        \n",
    "        if b is None and a is None:\n",
    "            b , a = signal.iirfilter(4,[lowcut/nqfreq,highcut/nqfreq])\n",
    "\n",
    "        nTrials = trial_lr.shape[1]\n",
    "        filt_trials = np.zeros((nChannels if selectedChannels is None else len(selectedChannels),nTrials,len(trialWin)))\n",
    "\n",
    "\n",
    "        for t in range(nTrials):\n",
    "            filt_trials[:,t,:] = signal.filtfilt(b,a,trial_lr[:,t,:],axis=1)\n",
    "\n",
    "        return filt_trials\n",
    "    \n",
    "    cl1, cl2 = classLabels\n",
    "\n",
    "    trials_filt[cl1] = bandPass(trials[cl1],8,12,sRate)\n",
    "    trials_filt[cl2] = bandPass(trials[cl2],8,12,sRate)\n",
    "\n",
    "    return trials_filt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import mlab\n",
    "\n",
    "def psd(trials, trialWindow, nChannels, sRate):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    trials: A 3D ndarray of shape (channels x trials x time)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trials_PSD: A 3D ndarray of shape (channels x trials x PSD) the PSD for each trial\n",
    "    \"\"\"\n",
    "\n",
    "    nTrials = trials.shape[1]\n",
    "    trials_PSD = np.zeros((nChannels,nTrials, int(len(trialWindow)/2)+1)) #Why?\n",
    "\n",
    "    for trial in range(nTrials):\n",
    "        for ch in range(nChannels):\n",
    "            #Calculate the PSD\n",
    "            \n",
    "            (PSD, freqs) = mlab.psd(trials[ch, trial , :], NFFT=len(trialWindow), Fs=sRate)\n",
    "            trials_PSD[ch, trial, :] = PSD\n",
    "\n",
    "    return trials_PSD, freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_psd(trial_PSDs,freqs,channel_IDXs,ymax,labels=None):\n",
    "\n",
    "    \"\"\" Plot the mean Power Spectral Density of left and right hand signals from \n",
    "        all trials at the given electrode channels \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    nChans = len(channel_IDXs)\n",
    "    nRows = int(np.ceil(nChans/3))\n",
    "    nCols = min(3,nChans)\n",
    "\n",
    "    #for channels in channel indexes\n",
    "    for i,ch in enumerate(channel_IDXs):\n",
    "        plt.subplot(nRows,nCols,i+1)\n",
    "\n",
    "        for cls in trial_PSDs.keys():\n",
    "            plt.plot(freqs,np.mean(trial_PSDs[cls][ch,:,:],axis=0),label=cls)\n",
    "\n",
    "        #plt.fill_betweenx(np.mean(trial_PSDs[\"left\"][ch,:,:],axis=0), 8, 12, color=\"green\", alpha=0.2)\n",
    "\n",
    "        plt.xlabel(\"Frequency in Hz\")\n",
    "        \n",
    "        plt.xlim(1,30)\n",
    "        plt.grid()\n",
    "        plt.ylim(0,ymax)\n",
    "\n",
    "        if labels is not None:\n",
    "            plt.legend(labels)\n",
    "        else:\n",
    "            plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following the standard bci classification paradigm outlined in \"The non-invasive Berlin Brain–Computer Interface: Fast acquisition of effective performance in untrained subjects\"\n",
    "#Benjamin Blankertz,a,⁎ Guido Dornhege,a Matthias Krauledat,a,b Klaus-Robert Müller, and Gabriel Curio\n",
    "\n",
    "def logvar(trials):\n",
    "    #trials has a shape of 59 x 100 x 200\n",
    "    return np.log(np.var(trials,axis=2))\n",
    "    #calculate variance along the sample (time sample) axis\n",
    "    #then calculate the log of the result\n",
    "\n",
    "    # Since VARIANCE of band-pass filtered signals\n",
    "    # is equal to band-power, CSP analysis is applied\n",
    "    # to approximately band-pass filtered signals in order\n",
    "    # to obtain an effective discrimination of mental states\n",
    "    # that are characterized by ERD/ERS effects ref:Optimizing Spatial filters for Robust EEG Single-Trial Analysis\n",
    "\n",
    "    # The log of the variance can be useful for data that exhibits exponential or power-law relationships,\n",
    "    # as it can help to compress the range of the data and make it easier to visualize and analyze.\n",
    "\n",
    "    # For example, consider a set of spatial filters with variances[1, 10, 100]. The log of the variances\n",
    "    # would be[0, 1, 2], which has a smaller range than the original data. This can be useful for data that\n",
    "    # has a wide range of values, as it can make it easier to visualize and analyze the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_logvar(trials, nChannels, classLabels):\n",
    "    \"\"\" Plot the mean log-var (logarithm of the variance) \"\"\"\n",
    "    plt.figure(figsize=(12,5))\n",
    "\n",
    "    x0 = np.arange(nChannels)\n",
    "    x1 = np.arange(nChannels) + 0.4\n",
    "\n",
    "    cl1,cl2 = classLabels\n",
    "\n",
    "    y0 = np.mean(trials[cl1],axis=1)\n",
    "    y1 = np.mean(trials[cl2],axis=1)\n",
    "\n",
    "    #axis 1 refers to the axis at position 1 in the dimension tuple\n",
    "    #in this case, the dimension tuple of trials[\"left\"] or trials[\"right\"]\n",
    "    # is (59,100)\n",
    "    #Hence the mean is calculated along the axis with 100 values\n",
    "    #Leaving a vector of shape (59,)\n",
    "\n",
    "\n",
    "    plt.bar(x0,y0, width=0.5, color=\"b\")\n",
    "    plt.bar(x1,y1, width=0.4, color=\"r\")\n",
    "\n",
    "    plt.xlim(-0.5,nChannels+0.5)\n",
    "\n",
    "    plt.gca().yaxis.grid(True)\n",
    "    plt.title(\"log-var of each channel\")\n",
    "    plt.xlabel(\"channels\")\n",
    "    plt.ylabel(\"log-var\")\n",
    "    plt.legend(classLabels)\n",
    "\n",
    "    #A plot of the log of the variance of the CSP transformed data can be useful for identifying patterns or\n",
    "    # trends in the data that may be indicative of differences between the two classes of signals.\n",
    "    # For example, if the log of the variance of the CSP transformed data is higher for one class than the\n",
    "    # other, it could indicate that the filters for that class are more discriminative.\n",
    "\n",
    "    # To choose the subset of filters that are most discriminative between the two classes of signals,\n",
    "    # it may be useful to plot the log of the variance of the CSP transformed data and examine the patterns\n",
    "    # or trends that emerge. The filters with the highest variance could be selected as the most discriminative,\n",
    "    # as they may contain the most information about the differences between the two classes.\n",
    "\n",
    "    #In the case below, it seems that the log of the variance of spatial filter 0 (column 0) is at its highest for\n",
    "    #left hand signals and its lowest for right hand singals, whereas, spatial filter 59, has its log-var at its highest\n",
    "    #right hand signals and its lowest for left hand signals. Hence, for each signal window (shape 59 x 1 x 200)\n",
    "    # We can extract the two most relevant spatial filters to determine whether it represents left or right.\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg\n",
    "\n",
    "def cov(trials):\n",
    "    \"\"\"Calculate the covariance for each trial and return their average\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trials - Array (channels x trials x samples) \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A covariance matrix containing the mean values of all covariance matrices generated from trials\n",
    "    \"\"\"\n",
    "    ntrials = trials.shape[1]\n",
    "\n",
    "    #Select all 59 channels (59 rows), then select the ith trial\n",
    "    #for each of those 59 rows along with all the columns (values) for that\n",
    "    # trial (resulting in a 59 x 400 matrix) and calculate the covariance matrix\n",
    "\n",
    "    covs = [np.cov(trials[:,i,:]) for i in range(ntrials)]\n",
    "\n",
    "    # covs consists of nTrials x 59 x 59 matrices\n",
    "    #Since covariance is calculated by the dot product of X and X.T\n",
    "    #Where X.T is the transpose of X [(59 x 400).dot((400 x 59))]\n",
    "\n",
    "    #print(np.array(covs).shape)\n",
    "\n",
    "    return np.mean(covs, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitening(sigma):\n",
    "    \"\"\"Calculate a whitening matrix for covariance matrix sigma.\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    sigma - A covariance matrix of shape N x N, where N is the number of channels for a given\n",
    "            trial. \n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    The whitened covariance matrix\n",
    "\n",
    "    \"\"\"\n",
    "    #In singular value decomposition(SVD), a matrix is decomposed into the product of\n",
    "    # three matrices: a left singular matrix, a diagonal matrix, and a right singular matrix.\n",
    "    # The diagonal matrix, called the singular value matrix, contains the singular values of the\n",
    "    # original matrix. The left and right singular matrices contain the left and right singular\n",
    "    # vectors, respectively.\n",
    "\n",
    "    # A whitening matrix is a diagonal matrix that is used to transform the singular value matrix\n",
    "    # so that it has the identity matrix as its diagonal. This is done by dividing each element on the\n",
    "    # diagonal of the singular value matrix by the square root of the corresponding singular value.\n",
    "\n",
    "    # The whitening matrix is useful in SVD because it can be used to decorrelate the singular vectors,\n",
    "    # which can simplify certain computations and make it easier to interpret the results of\n",
    "    # the decomposition. For example, in dimensionality reduction, whitening the singular value matrix\n",
    "    # can help to remove some of the redundancy in the data and make it easier to identify the underlying\n",
    "    # structure of the data.\n",
    "\n",
    "    U, l, _ = linalg.svd(sigma) # l is a vector of singular values U is the left singular matrix\n",
    "    return U.dot(np.diag(l ** -0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def csp(trials_r, trials_l):\n",
    "    \"\"\"Calculate the CSP transformation matrix W\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    trials_r - Array(channels x trials x samples) containing right hand movement trials\n",
    "    trials_l - Array(channels x trials x samples) containing left hand movement trials\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Mixing matrix W\n",
    "    \"\"\"\n",
    "    cov_l = cov(trials_l)\n",
    "    cov_r = cov(trials_r)\n",
    "\n",
    "    # apply whitening to covariance matrices\n",
    "    P = whitening(cov_l + cov_r)\n",
    "    cov_l = P @ cov_l @ P.T\n",
    "    cov_r = P @ cov_r @ P.T\n",
    "    \n",
    "    \n",
    "    # According to [Filter bank common spatial pattern algorithm on BCI competition IV Datasets 2a and 2b]\n",
    "    # W can be calculated by W = eig(S1, S1 + S2),where W, S1, and S2 here represents W b, Σb,1, and Σb,2 respectively\n",
    "    # Σb,1 and Σb,2 are estimates of the covariance matrices of the band-pass filtered EEG measurements of the respective motor imagery action (left, right)\n",
    "\n",
    "    _,W = scipy.linalg.eigh(cov_l, cov_l + cov_r)\n",
    "\n",
    "    # project data onto CSP components\n",
    "    W = P.T @ W\n",
    "\n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mix(W, trials, trialWin, nChannels, selectedChannels=None):\n",
    "    \"\"\"Apply a decomposition matrix to each trial (basically multiply W with the EEG signal matrix)\"\"\"\n",
    "    ntrials = trials.shape[1]\n",
    "\n",
    "\n",
    "    trials_csp = np.zeros((nChannels if selectedChannels is None else len(selectedChannels) , ntrials, len(trialWin)))\n",
    "\n",
    "\n",
    "    for i in range(ntrials):\n",
    "        trials_csp[:,i,:] = W.T.dot(trials[:,i,:])\n",
    "\n",
    "    return trials_csp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(cl1,cl2,classLabels):\n",
    "    \"\"\" Display scatter plot of the distribution left and right motor imagery trials\"\"\"\n",
    "    plt.figure()\n",
    "    plt.scatter(cl1[0,:],cl1[-1,:],color=\"b\")\n",
    "    plt.scatter(cl2[0,:],cl2[-1,:],color=\"r\")\n",
    "    plt.xlabel(\"First Component\")\n",
    "    plt.ylabel(\"Last Component\")\n",
    "    plt.legend(classLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def label_data(data,label,foldNum):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data - An array of dimensions observation x features\n",
    "    label the desired label\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    newData - An dataframe of with columns F1...Fn and label\n",
    "    \"\"\"\n",
    "\n",
    "    nTrainSamples = data.shape[0]\n",
    "    nFeatures = data.shape[1]\n",
    "\n",
    "    featureColumns = [f\"F{x}\" for x in range(1,nFeatures+1)]\n",
    "\n",
    "    newData = pd.DataFrame(data,columns=featureColumns)\n",
    "\n",
    "    newData[\"Labels\"] = np.array([label for x in range(nTrainSamples)])\n",
    "\n",
    "    # Apply fold num\n",
    "    newData[\"Fold\"] = np.random.randint(1,foldNum+1,nTrainSamples)\n",
    "\n",
    "    return newData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def tuneModelHyperParams(train_X, train_y, test_X, test_y):\n",
    "\n",
    "    metric_model_performance = defaultdict(dict)\n",
    "\n",
    "    for scoring in [\"accuracy\",\"roc_auc\",\"f1\"]:\n",
    "\n",
    "        ################################### SVC ##########################################################\n",
    "\n",
    "        param_grid = {'C': [0.0001,0.001,0.01,1,10,100,1000],\n",
    "                    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                    'kernel':[\"rbf\",\"linear\"],\n",
    "                    'class_weight':['balanced', None]}\n",
    "\n",
    "        gridSVM = GridSearchCV(estimator=SVC(probability=True), param_grid=param_grid,scoring=scoring, cv=5)\n",
    "\n",
    "        gridSVM.fit(train_X, train_y)\n",
    "\n",
    "        preds = gridSVM.best_estimator_.predict(test_X)\n",
    "\n",
    "        metric_model_performance[scoring][\"SVC\"] = gridSVM.best_estimator_, sum(preds == test_y)/len(test_y)\n",
    "\n",
    "\n",
    "        ################################### Logisitic Regression ##########################################\n",
    "\n",
    "        param_grid = {'penalty': ['l1','l2'],\n",
    "                      'C':list(np.logspace(-3,3)),\n",
    "                      'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "                      'class_weight':['balanced', None]}\n",
    "\n",
    "        # Create the grid search object\n",
    "        gridLogReg = GridSearchCV(estimator=LogisticRegression(), param_grid=param_grid,scoring=scoring, cv=5)\n",
    "\n",
    "        gridLogReg.fit(train_X,train_y)\n",
    "\n",
    "        preds = gridLogReg.best_estimator_.predict(test_X)\n",
    "\n",
    "        metric_model_performance[scoring][\"LogReg\"] = gridLogReg.best_estimator_, sum(preds == test_y)/len(test_y)\n",
    "\n",
    "\n",
    "        ######################################### LDA ########################################################\n",
    "\n",
    "        param_grid = {'solver': ['svd', 'lsqr', 'eigen'],'shrinkage': np.arange(0,1,0.1)}\n",
    "\n",
    "        gridLDA = GridSearchCV(estimator=LDA(), param_grid=param_grid,scoring=scoring, cv=5)\n",
    "\n",
    "        gridLDA.fit(train_X, train_y)\n",
    "\n",
    "        preds = gridLDA.best_estimator_.predict(test_X)\n",
    "\n",
    "        metric_model_performance[scoring][\"LDA\"] = gridLDA.best_estimator_, sum(preds == test_y)/len(test_y)\n",
    "\n",
    "    return metric_model_performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "def featureExtraction(data, split_percentage, ExtractionType = None, b=None, a=None, selectedChannels=None, trialWinStart=0, trialWinEnd=4):\n",
    "\n",
    "    \"\"\"Extract csp features from training data\"\"\"\n",
    "    \n",
    "    eeg = data[\"cnt\"].T \n",
    "\n",
    "    nChannels, nSamples = eeg.shape\n",
    "\n",
    "    channelNames,sRate,classLabels,eventOnsets,eventCodes,labels = extractInfo(data,nSamples)\n",
    "\n",
    "    cl1, cl2 = classLabels #left | right\n",
    "    \n",
    "\n",
    "    trialWindow = np.arange(int(trialWinStart*sRate),int(trialWinEnd*sRate))\n",
    "\n",
    "    ####### RETURN MOTION INTENT STATE AND IDLE STATE TRIALS ########\n",
    "\n",
    "    trials, idleStateTrials = getTrials(classLabels,\n",
    "                        np.unique(eventCodes),\n",
    "                        trialWindow,\n",
    "                        eeg,\n",
    "                        eventCodes,\n",
    "                        eventOnsets,\n",
    "                        sRate,\n",
    "                        nChannels,\n",
    "                        selectedChannels = selectedChannels)\n",
    "\n",
    "\n",
    "    ######## RETURN FILTERED MOTION INTENT TRIALS AND IDLE STATE TRIALS#######\n",
    "    \n",
    "\n",
    "    filteredTrials = getFilteredTrials(trials,\n",
    "                                       trialWindow,\n",
    "                                       nChannels,\n",
    "                                       sRate,\n",
    "                                       selectedChannels=selectedChannels,\n",
    "                                       b=b,\n",
    "                                       a=a,\n",
    "                                       classLabels=classLabels)\n",
    "    \n",
    "\n",
    "    filteredIdleTrials = getFilteredTrials(idleStateTrials,\n",
    "                                           trialWindow,\n",
    "                                           nChannels,\n",
    "                                           sRate,\n",
    "                                           selectedChannels=selectedChannels,\n",
    "                                           b=b,\n",
    "                                           a=a,\n",
    "                                           classLabels=classLabels)\n",
    "    \n",
    "\n",
    "    ######### COMBINE IDLE TRIALS AND MOTION INTENT CLASSES INTO TWO SUPERCLASSES  #########\n",
    "    \n",
    "    concatFilteredIdleTrials = np.concatenate((filteredIdleTrials[cl1],filteredIdleTrials[cl2]),axis=1)\n",
    "    concatFilteredMotionIntentTrials = np.concatenate((filteredTrials[cl1],filteredTrials[cl2]),axis=1)\n",
    "    \n",
    "    \n",
    "    ##### CALCULTE A CSP TRANSORMATION MATRIX AND APPLY IT TO THE DATA USING THE IDLE STATE CLASS ########\n",
    "\n",
    "\n",
    "    idle_MotionIntentTrainingData = {\"idle\": concatFilteredIdleTrials,\n",
    "                                    \"motion\":concatFilteredMotionIntentTrials}\n",
    "    \n",
    "    W_idleMotionIntentTranformationMatrix = csp(idle_MotionIntentTrainingData[\"idle\"],idle_MotionIntentTrainingData[\"motion\"])\n",
    "\n",
    "    idle_MotionIntentTrainingData = {\n",
    "        \"idle\": apply_mix(W_idleMotionIntentTranformationMatrix, idle_MotionIntentTrainingData[\"idle\"], trialWindow,nChannels,selectedChannels=selectedChannels),\n",
    "        \"motion\":apply_mix(W_idleMotionIntentTranformationMatrix, idle_MotionIntentTrainingData[\"motion\"], trialWindow,nChannels,selectedChannels=selectedChannels)\n",
    "    }\n",
    "\n",
    "\n",
    "    ##### CALCULTE A CSP TRANSORMATION MATRIX FOR ORIGINAL LEFT HAND IMAGERY AND RIGHT HAND IMAGERY AND APPLY IT TO THE DATA ########\n",
    "    train = {cl1: filteredTrials[cl1],\n",
    "            cl2: filteredTrials[cl2]}\n",
    "\n",
    "    W = csp(train[cl2],train[cl1])\n",
    "\n",
    "    train = {\n",
    "    cl1 : apply_mix(W,train[cl1],trialWindow,nChannels,selectedChannels=selectedChannels),\n",
    "    cl2 : apply_mix(W,train[cl2],trialWindow,nChannels,selectedChannels=selectedChannels)\n",
    "    }\n",
    "\n",
    "    ##### CALCULATE THE LOGVAR FOR BOTH TRANSFORMED SETS OF DATA #####\n",
    "\n",
    "    idle_MotionIntentTrainingData[\"idle\"] = logvar(idle_MotionIntentTrainingData[\"idle\"])\n",
    "    idle_MotionIntentTrainingData[\"motion\"] = logvar(idle_MotionIntentTrainingData[\"motion\"])\n",
    "\n",
    " \n",
    "    train[cl1] = logvar(train[cl1])\n",
    "    train[cl2] = logvar(train[cl2])\n",
    "\n",
    "\n",
    "    #### CHOOSE THE IDLE COMPONENTS FOR EACH OF THE NEW CSP FEATURES FOR THE TWO TRANSFORMED SETS OF DATA #####\n",
    "    comp = [0,-1]\n",
    "\n",
    "    idle_MotionIntentTrainingData[\"idle\"] = idle_MotionIntentTrainingData[\"idle\"][comp,:]\n",
    "    idle_MotionIntentTrainingData[\"motion\"] = idle_MotionIntentTrainingData[\"motion\"][comp,:] \n",
    "\n",
    "\n",
    "    train[cl1] = train[cl1][comp,:]\n",
    "    train[cl2] = train[cl2][comp,:]\n",
    "\n",
    "\n",
    "    #### LABEL DATA AND STORE IN A DATAFRAME FOR LATER PROCESSING ######\n",
    "\n",
    "    train_idle_dataframe = label_data(idle_MotionIntentTrainingData[\"idle\"].T,0,5)\n",
    "    train_motionIntent_dataframe = label_data(idle_MotionIntentTrainingData[\"motion\"].T,1,5)\n",
    "\n",
    "    train_l_df = label_data(train[cl1].T,-1,5) \n",
    "    train_r_df = label_data(train[cl2].T,1,5)\n",
    "\n",
    "    ###### CONCATE DATAFRAMES OF DIFFERENT CLASSES INTO ONE DATA FRAME #####\n",
    "\n",
    "    train_idle_motionIntent_comb = pd.concat([train_idle_dataframe,train_motionIntent_dataframe])\n",
    "\n",
    "    train_comb = pd.concat([train_l_df,train_r_df])\n",
    "\n",
    "    nCols = len(train_comb.columns)\n",
    "\n",
    "    if split_percentage == 1:\n",
    "        if ExtractionType is None:\n",
    "\n",
    "            X = train_comb.iloc[:,:nCols-2]\n",
    "            y = train_comb.iloc[:,nCols-2]\n",
    "\n",
    "\n",
    "            trainDataStore = {} #Stores different training data for each resampling method\n",
    "\n",
    "            ######################################################## RESAMPLING #################################################################\n",
    "\n",
    "            for name,resampler in [(\"RO\",RandomOverSampler(random_state=42)),\n",
    "                                    (\"SMOTE\",SMOTE(random_state=42)),\n",
    "                                    (\"RU\",RandomUnderSampler(random_state=42)),\n",
    "                                    (\"CC\",ClusterCentroids(random_state=42)),\n",
    "                                    (\"None\",None)]:\n",
    "\n",
    "\n",
    "\n",
    "                if not resampler:\n",
    "                    train_comb = pd.DataFrame(X,columns=[\"F1\",\"F2\"])\n",
    "                    train_comb[\"Labels\"] = y\n",
    "\n",
    "                    #store this instance of training data\n",
    "                    trainDataStore[name] = train_comb.copy()\n",
    "                    continue\n",
    "\n",
    "                #Resample training data only\n",
    "                train_comb_X_reSamp, train_comb_y_reSamp = resampler.fit_resample(X,y)\n",
    "\n",
    "\n",
    "\n",
    "                train_comb = pd.DataFrame(train_comb_X_reSamp,columns=[\"F1\",\"F2\"])\n",
    "                train_comb[\"Labels\"] = train_comb_y_reSamp\n",
    "\n",
    "                #store this instance of training data\n",
    "                trainDataStore[name] = train_comb.copy()\n",
    "\n",
    "\n",
    "            return trainDataStore, W, comp\n",
    "        \n",
    "        elif ExtractionType == \"idle_motionIntent\":\n",
    "            X = train_idle_motionIntent_comb.iloc[:,:nCols-2]\n",
    "            y = train_idle_motionIntent_comb.iloc[:,nCols-2]\n",
    "            \n",
    "\n",
    "            train_idle_motionIntent_comb = pd.DataFrame(X,columns=[\"F1\",\"F2\"])\n",
    "            train_idle_motionIntent_comb[\"Labels\"] = y\n",
    "\n",
    "            return train_idle_motionIntent_comb, W_idleMotionIntentTranformationMatrix, comp\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        if ExtractionType is None:\n",
    "\n",
    "            #choosing not to balance data as this is more representative of the evaluation data and a possible real-world\n",
    "            #application where the decision of left or right cannot be expected to be balanced\n",
    "\n",
    "            #I can shuffle data since trials can be considered as indepedent samples with no temporal relationship\n",
    "            X = train_comb.iloc[:,:nCols-2]\n",
    "            y = train_comb.iloc[:,nCols-2]\n",
    "\n",
    "        \n",
    "            train_comb_X, test_comb_X, train_comb_y,test_comb_y = train_test_split(X,y,train_size=split_percentage,random_state=42)\n",
    "            \n",
    "            #samples may be heavily skewed towards one class in the training data (class imbalance)\n",
    "            #We must resample the calibration data\n",
    "\n",
    "\n",
    "            trainDataStore = {} #Stores different training data for each resampling method\n",
    "\n",
    "            ######################################################## RESAMPLING ################################################################# \n",
    "\n",
    "            for name,resampler in [(\"RO\",RandomOverSampler(random_state=42)),\n",
    "                                    (\"SMOTE\",SMOTE(random_state=42)),\n",
    "                                    (\"RU\",RandomUnderSampler(random_state=42)),\n",
    "                                    (\"CC\",ClusterCentroids(random_state=42)),\n",
    "                                    (\"None\",None)]:\n",
    "                \n",
    "                \n",
    "                \n",
    "                if not resampler:\n",
    "                    train_comb = pd.DataFrame(train_comb_X,columns=[\"F1\",\"F2\"])\n",
    "                    train_comb[\"Labels\"] = train_comb_y\n",
    "\n",
    "                    #store this instance of training data\n",
    "                    trainDataStore[name] = train_comb.copy()\n",
    "                    continue\n",
    "                \n",
    "                #Resample training data only \n",
    "                train_comb_X_reSamp, train_comb_y_reSamp = resampler.fit_resample(train_comb_X,train_comb_y)\n",
    "                \n",
    "                \n",
    "\n",
    "                train_comb = pd.DataFrame(train_comb_X_reSamp,columns=[\"F1\",\"F2\"])\n",
    "                train_comb[\"Labels\"] = train_comb_y_reSamp\n",
    "                \n",
    "                #store this instance of training data \n",
    "                trainDataStore[name] = train_comb.copy()\n",
    "\n",
    "            test_comb = pd.DataFrame(test_comb_X,columns=[\"F1\",\"F2\"])\n",
    "            test_comb[\"Labels\"] = test_comb_y\n",
    "\n",
    "            return trainDataStore, test_comb, W, comp\n",
    "        \n",
    "        elif ExtractionType == \"idle_motionIntent\":\n",
    "\n",
    "            X = train_idle_motionIntent_comb.iloc[:,:nCols-2]\n",
    "            y = train_idle_motionIntent_comb.iloc[:,nCols-2]\n",
    "\n",
    "            train_idle_motionIntent_comb_X, test_idle_motionIntent_comb_X, train_idle_motionIntent_comb_y,test_idle_motionIntent_comb_y = train_test_split(X,y,train_size=split_percentage,random_state=42)\n",
    "            \n",
    "            train_idle_motionIntent_comb = pd.DataFrame(train_idle_motionIntent_comb_X,columns=[\"F1\",\"F2\"])\n",
    "            train_idle_motionIntent_comb[\"Labels\"] = train_idle_motionIntent_comb_y\n",
    "\n",
    "            test_idle_motionIntent_comb = pd.DataFrame(test_idle_motionIntent_comb_X,columns=[\"F1\",\"F2\"])\n",
    "            test_idle_motionIntent_comb[\"Labels\"] = test_idle_motionIntent_comb_y\n",
    "\n",
    "            return train_idle_motionIntent_comb, test_idle_motionIntent_comb, W_idleMotionIntentTranformationMatrix, comp\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def testClassifier(rawData,trialWinStart,trialWinEnd,percentSplit,b=None,a=None,selectedChannels=None,resampler=None):\n",
    "\n",
    "    \"\"\" Extract the best classifier performace from training data \"\"\"\n",
    "    \n",
    "    #It may not yield the best results testing this classifier on data with a different trial \n",
    "    # width or start time since the data being tested is extracted using a different decomposition matrix (W) from the \n",
    "    # CSP algorithm. As the classifier being tested was initially fit to data extracted using a different decompostion matrix, \n",
    "    # poor performance is a likely result. It may be that in order to test the effect of increasing or decreasing the trial window \n",
    "    # length or the trial window start point, entirely new classifier tuning is required for each new window.\n",
    "    \n",
    "    if percentSplit < 1:\n",
    "    \n",
    "        trainDataStore, testData, W, _ = featureExtraction(rawData,percentSplit,\n",
    "                                                        selectedChannels=selectedChannels,\n",
    "                                                        trialWinStart=trialWinStart,\n",
    "                                                        trialWinEnd=trialWinEnd,\n",
    "                                                        b = b,\n",
    "                                                        a = a)\n",
    "    else:\n",
    "        trainDataStore,  W, _ = featureExtraction(rawData,percentSplit,\n",
    "                                                        selectedChannels=selectedChannels,\n",
    "                                                        trialWinStart=trialWinStart,\n",
    "                                                        trialWinEnd=trialWinEnd,\n",
    "                                                        b = b,\n",
    "                                                        a = a)\n",
    "    \n",
    "\n",
    "    trainData = trainDataStore[resampler] if resampler is not None else trainDataStore[\"None\"]\n",
    "    \n",
    "    \n",
    "    nCols = len(trainData.columns)\n",
    "    ########################################## CLASSIFIER TUNING ####################################################\n",
    "\n",
    "    bestModels = tuneModelHyperParams(trainData.iloc[:,:nCols-1],\n",
    "                                      trainData.iloc[:,nCols-1],\n",
    "                                      testData.iloc[:,:nCols-1],\n",
    "                                      testData.iloc[:,nCols-1])\n",
    "    \n",
    "\n",
    "    bestModel, bestPerformance = None, 0\n",
    "\n",
    "    for metric in bestModels:\n",
    "        for model in bestModels[metric]:\n",
    "            mod, perf = bestModels[metric][model]\n",
    "\n",
    "            if perf > bestPerformance:\n",
    "                bestMetric, bestModel, bestPerformance = metric, mod, perf\n",
    "\n",
    "    return bestPerformance, bestModel, W, bestMetric, bestModels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startRunningClassifier(evalData,calibratedModel,idleStateClassifier,comp, W_train, W_idle_motionIntent, trialWinStart,trialWinEnd,b=None, a=None):\n",
    "    \"\"\" Extract class probabilities from evaluation test data for each time sample\"\"\"\n",
    "    \n",
    "    #Extracting Sampling Rate\n",
    "    sRate = evalData[\"nfo\"][0][0][0][0][0]\n",
    "\n",
    "    evalEEG = evalData[\"cnt\"].T \n",
    "   \n",
    "    nSamples = evalEEG.shape[1] \n",
    "\n",
    "    trialWindow = np.arange(int(trialWinStart*sRate),int(trialWinEnd*sRate))\n",
    "\n",
    "    preds = []\n",
    "\n",
    "    features = []\n",
    "\n",
    "    #Extract features first\n",
    "    try:\n",
    "        n = 0\n",
    "        for i in range(nSamples):\n",
    "            if n == 50000:\n",
    "                break\n",
    "            #capture signal in sliding window\n",
    "            captured_signal = evalEEG[:,i+trialWindow]\n",
    "\n",
    "            ### CHECK WHETHER SIGNAL IS IDLE STATE OR MOTION INTENT STATE #### \n",
    "\n",
    "            #filter captured signal\n",
    "            nqfreq = 0.5*sRate\n",
    "            if b is None and a is None:\n",
    "                b , a = signal.iirfilter(6,[8/nqfreq,12/nqfreq])\n",
    "\n",
    "            filtered_idle_motionIntent_test_trial = signal.filtfilt(b,a,captured_signal,axis=1)\n",
    "\n",
    "            #Extract features from transformed data\n",
    "            spatialFilters_idle_motionIntent = W_idle_motionIntent.T.dot(filtered_idle_motionIntent_test_trial)\n",
    "            spatialFilters_idle_motionIntent = spatialFilters_idle_motionIntent[comp,:]\n",
    "\n",
    "            feature_idle_motionIntent = np.log(np.var(spatialFilters_idle_motionIntent,axis=1)).T\n",
    "\n",
    "            #check result if idleState classifier\n",
    "            #print(idleStateClassifier.predict_proba(pd.DataFrame([feature_idle_motionIntent],columns=[\"F1\",\"F2\"])))\n",
    "            idle_motionIntent_state = idleStateClassifier.predict(pd.DataFrame([feature_idle_motionIntent],columns=[\"F1\",\"F2\"]))\n",
    "\n",
    "            if idle_motionIntent_state[0] == 1:\n",
    "                if b is None and a is None:\n",
    "                    b , a = signal.iirfilter(6,[8/nqfreq,12/nqfreq])\n",
    "\n",
    "                filtered_test_trial = signal.filtfilt(b,a,captured_signal,axis=1)\n",
    "\n",
    "                #Extract features from transformed data\n",
    "                spatialFilters = W_train.T.dot(filtered_test_trial)\n",
    "\n",
    "                spatialFilters = spatialFilters[comp,:]\n",
    "\n",
    "                feature = np.log(np.var(spatialFilters,axis=1)).T\n",
    "\n",
    "                features.append(feature)\n",
    "            \n",
    "               \n",
    "            else:\n",
    "                features.append(np.array([0,0]))\n",
    "\n",
    "            n += 1\n",
    "\n",
    "    \n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "  \n",
    "   \n",
    "    for f in features:\n",
    "      \n",
    "        if f[0] == f[1] == 0:\n",
    "            preds.extend([[0,0]])\n",
    "            continue\n",
    "\n",
    "        classProbabilities = calibratedModel.predict_proba(pd.DataFrame([f],columns=[\"F1\",\"F2\"]))\n",
    "    \n",
    "        preds.extend(classProbabilities)       \n",
    "\n",
    "  \n",
    "    \n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFilterBank(fs):\n",
    "    \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        fs: Sampling frequency\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        filterBank: A dictionary with keys represented by a frequency band; (lower bound, upper bound)\n",
    "                    and values as numerator (b) and denominator (a) coefficients of the iirfilter\n",
    "    \"\"\"\n",
    "    \n",
    "    filterBank = {}\n",
    "\n",
    "    freq_bands = [(8,12),(8,15),(13,30)]\n",
    "\n",
    "    for lowcut, highcut in freq_bands:\n",
    "        nqfreq = 0.5*fs\n",
    "        b , a = signal.iirfilter(4,[lowcut/nqfreq,highcut/nqfreq])\n",
    "        filterBank[(lowcut,highcut)] = (b,a)\n",
    "\n",
    "    return filterBank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWindowLength(data,modelNames,split):\n",
    "\n",
    "    \"\"\" Extract best performance from trial window length tuning \"\"\"\n",
    "    \n",
    "    bestTime = None\n",
    "    bestPerformance = 0\n",
    "    bestEstimator = None\n",
    "\n",
    "    \n",
    "    for model in modelNames:\n",
    "        \n",
    "        accVals = {}\n",
    "        bestModelPerformance = 0\n",
    "        bestModelEstimator = None\n",
    "        bestModelTime = None\n",
    "\n",
    "        for i in np.linspace(1,5,9):\n",
    "            accVals[i-0.5], estimator, W = testClassifier(data,0.5,i,split,model)\n",
    "            \n",
    "            if accVals[i-0.5] > bestModelPerformance:\n",
    "                bestModelPerformance = accVals[i-0.5]\n",
    "                bestModelEstimator = estimator\n",
    "                bestModelTime = i-0.5\n",
    "\n",
    "        if bestModelPerformance > bestPerformance:\n",
    "            bestPerformance = bestModelPerformance\n",
    "            bestEstimator = bestModelEstimator\n",
    "            bestTime = bestModelTime\n",
    "\n",
    "        #plot acc Val\n",
    "        x, y = zip(*accVals.items())\n",
    "        plt.plot(x,y,label=f\"{model}({bestModelPerformance})\")\n",
    "    \n",
    "    plt.axvline(x=bestTime, color='purple', ls='--', lw=1.5, label=f\"Best window length ({bestTime})\")\n",
    "    plt.legend()\n",
    "    \n",
    "\n",
    "    return bestEstimator, W\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWindowStartTime(data,split,bestWindowEnd,times=None):\n",
    "\n",
    "    \"\"\" Extract best performance from trial window start time tuning \"\"\"\n",
    "\n",
    "    bestTime = None\n",
    "    bestPerformance = 0\n",
    "    bestEstimator = None\n",
    "\n",
    "    accVals = {}\n",
    "    \n",
    "    times = np.arange(0,2.1,0.1) if times is None else times\n",
    "\n",
    "    for i in times:\n",
    "        accVals[i], estimator, W , _ = testClassifier(data,i,bestWindowEnd,split)\n",
    "\n",
    "        if accVals[i] > bestPerformance:\n",
    "            bestPerformance = accVals[i]\n",
    "            bestEstimator = estimator\n",
    "            bestTime = i\n",
    "\n",
    "\n",
    "        x, y = zip(*accVals.items())\n",
    "        plt.plot(x,y,label=f\"{type(estimator).__name__}({accVals[i]})\")\n",
    "   \n",
    "    plt.axvline(x=bestTime, color='purple', ls='--', lw=1.5, label=f\"Best start time({bestTime})\")\n",
    "    plt.legend()\n",
    "    \n",
    "    return bestEstimator, W\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testWindowStartTime_Length(data,modelNames,split):\n",
    "\n",
    "    bestStartTimeLengthCombination = None\n",
    "    bestPerformance = 0\n",
    "    bestEstimator = None\n",
    "\n",
    "    for model in modelNames:\n",
    "        \n",
    "        accVals = {}\n",
    "        bestModelPerformance = 0\n",
    "        bestModelEstimator = None\n",
    "        bestModelStartTimeLengthCombination = None\n",
    "\n",
    "        for windowStartTime in np.arange(0,2.1,0.1):\n",
    "            for windowLength in np.linspace(1,5,9):\n",
    "                accVals[(windowStartTime,windowLength)], estimator, W = testClassifier(data,\n",
    "                                                                                       windowStartTime,\n",
    "                                                                                       windowStartTime + windowLength,\n",
    "                                                                                       split,\n",
    "                                                                                       model)\n",
    "                \n",
    "                if accVals[windowStartTime,windowLength] > bestModelPerformance:\n",
    "                    bestModelPerformance = accVals[windowStartTime,windowLength]\n",
    "                    bestModelEstimator = estimator\n",
    "                    bestModelStartTimeLengthCombination = (windowStartTime, windowLength)\n",
    "\n",
    "        if bestModelPerformance > bestPerformance:\n",
    "            bestPerformance = bestModelPerformance\n",
    "            bestEstimator = bestModelEstimator\n",
    "            bestStartTimeLengthCombination = bestModelStartTimeLengthCombination \n",
    "\n",
    "        \n",
    "    print(bestStartTimeLengthCombination)\n",
    "    return bestEstimator, W\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testFrequencyBand(rawData,filterBank,split,selectedChannels=None, trialWinStart=None, trialWinEnd=None, resampler=None):\n",
    "\n",
    "    \"\"\" Extract best performance from frequency band tuning \"\"\"\n",
    "\n",
    "\n",
    "    totalBestBandPerformance = 0\n",
    "    bandFreqRes = {}\n",
    "    bestEstimator = None\n",
    "    \n",
    "    bestBand = None\n",
    "    \n",
    "    for lower,upper in filterBank.keys():\n",
    "\n",
    "        b, a = filterBank[lower,upper]\n",
    "        \n",
    "        bestBandPerformanceVal = 0\n",
    "        bestBandEstimator = None\n",
    "       \n",
    "        bestBandPerformanceVal,  bestBandEstimator, W, bestBandPerformanceMetric, allBandMetricPerformances = testClassifier(rawData,trialWinStart,trialWinEnd,split,b=b,a=a,selectedChannels=selectedChannels, resampler=resampler)\n",
    "        \n",
    "        if bestBandPerformanceVal > totalBestBandPerformance:\n",
    "            bestBand = lower,upper\n",
    "            totalBestBandPerformance = bestBandPerformanceVal\n",
    "            bestEstimator = bestBandEstimator\n",
    "\n",
    "        bandFreqRes[lower,upper] = (b,a)\n",
    "        print(f\"{lower}-{upper} : {bestBandPerformanceVal} ({bestBandPerformanceMetric})\")\n",
    "        print()\n",
    "        print(f\"All Metrics: {allBandMetricPerformances}\")\n",
    "        print(\"************************\")\n",
    "\n",
    "    \n",
    "    return bestBand, bestEstimator, bandFreqRes[bestBand], W\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
